\chapter{Implementierung}

\section{Projektstruktur}

Die Projektstruktur ist so gewählt, dass der zentrale Anwendungsteil den vollständigen Code für das Kernmodul enthält. 
Innerhalb dieses Moduls werden die verschiedenen Rollen des Systems klar voneinander getrennt umgesetzt. 
Komponenten, die nicht direkt zum Kerngeschäft gehören, wie Infrastrukturkomponenten oder Tests, 
sind in eigenständige Projekte ausgelagert. Dadurch wird die Wartbarkeit verbessert und eine klare Trennung 
der Verantwortlichkeiten erreicht. Die Gesamtstruktur des Projekts ist in Abbildung~\ref{fig:project-structure} dargestellt.

\begin{figure}[H]
\centering
\definecolor{folderbg}{RGB}{124,166,198}
\definecolor{folderborder}{RGB}{110,144,169}

\def\Size{4pt}
\tikzset{
  folder/.pic={
    \filldraw[draw=folderborder,top color=folderbg!50,bottom color=folderbg]
      (-1.05*\Size,0.2\Size+5pt) rectangle ++(.75*\Size,-0.2\Size-5pt);
    \filldraw[draw=folderborder,top color=folderbg!50,bottom color=folderbg]
      (-1.15*\Size,-\Size) rectangle (1.15*\Size,\Size);
  }
}

\begin{forest}
  for tree={
    font=\ttfamily,
    grow'=0,
    child anchor=west,
    parent anchor=south,
    anchor=west,
    calign=first,
    inner xsep=7pt,
    edge path={
      \noexpand\path [draw, \forestoption{edge}]
      (!u.south west) +(7.5pt,0) |- (.child anchor) pic {folder} \forestoption{edge label};
    },
    before typesetting nodes={
      if n=1 {insert before={[,phantom]}} {}
    },
    fit=band,
    before computing xy={l=15pt},
  }
[BachelorAkkaNet
  [FormulaOneAkkaNet
    [Config]
    [Ingress]
    [Coordinator]
    [ShardRegion]
  ]
  [Infrastructure
    [General]
    [PubSub]
    [ShardRegion]
  ]
  [Client]
  [Tests]
]
\end{forest}
\caption{Gesamtstruktur des Projekts}
\label{fig:project-structure}
\end{figure}

Die modulare Struktur des Projekts stellt sicher, dass die implementierten Rollen des Systems klar voneinander 
abgegrenzt sind. Jede Modulkomponente enthält ausschließlich die für ihre Rolle relevanten Aktorimplementierungen 
und Logik. Die einzige gemeinsam genutzte Komponente ist die zentrale Konfiguration, die im Ordner 
\textit{Config} abgelegt ist. Sie stellt sicher, dass alle Module konsistent in das .NET-Hostingmodell eingebunden 
werden können.

Das Projekt \textit{Infrastructure} umfasst wiederverwendbare Funktionen und Hilfskomponenten, die sowohl von den 
Hauptmodulen als auch von den Systemtests und dem Client genutzt werden. Im \textit{Client}-Projekt erfolgt die 
Darstellung und Auswertung der erfassten Daten, wodurch eine externe Visualisierung des Systemzustands möglich wird.

Für die Implementierung wurden zentrale Bibliotheken aus dem Akka.NET-Ökosystem verwendet. 
Dazu gehören Pakete für Clusterbildung, Sharding, Persistenz und Stream-Verarbeitung. 
Zusätzlich kommen Hosting-Erweiterungen zum Einsatz, welche die Konfiguration der Cluster- 
und Persistenzkomponenten über das .NET-Hostingmodell ermöglichen. Ergänzend werden Npgsql 
für den Datenbankzugriff und Serilog für das Logging eingesetzt. Tabelle~\ref{tab:packages} 
gibt einen Überblick über die relevanten Kernpakete.


\begin{table}[H]
\centering
\begin{tabular}{l l}
\textbf{Paket} & \textbf{Version} \\
\hline
Akka & 1.5.54 \\
Akka.Cluster & 1.5.54 \\
Akka.Cluster.Sharding & 1.5.54 \\
Akka.Hosting & 1.5.53 \\
Akka.Cluster.Hosting & 1.5.53 \\
Akka.Persistence & 1.5.54 \\
Akka.Persistence.Sql & 1.5.53 \\
Akka.Persistence.Hosting & 1.5.53 \\
Akka.Persistence.Sql.Hosting & 1.5.53 \\
Akka.Streams & 1.5.54 \\
Akka.Serialization.Hyperion & 1.5.54 \\
Npgsql & 9.0.4 \\
Serilog & 4.3.0 \\
\end{tabular}
\caption{Verwendete Kernbibliotheken und Versionen}
\label{tab:packages}
\end{table}

Die ausgewählten Pakete decken die zentralen technischen Anforderungen des Systems ab. Akka.Cluster und Akka.Cluster.Sharding 
ermöglichen eine verteilte und fehlertolerante Verarbeitung der eingehenden Daten. Akka.Persistence und die zugehörigen 
SQL-Erweiterungen stellen sicher, dass zustandsbehaftete Entitäten konsistent wiederhergestellt werden können. Akka.Streams 
wird für die kontrollierte Verarbeitung der Datenströme eingesetzt. Mit den Hosting-Erweiterungen wird eine einheitliche 
Konfiguration über das .NET-Hostingmodell ermöglicht, wodurch die Initialisierung des Clusters sowie der Persistence-Komponenten 
vereinfacht wird. Serilog und Npgsql ergänzen die Architektur durch Logging und Datenbankanbindung.

\section{Konfiguration und Initialisierung des Clusters}

\subsection{HOCON-Konfiguration}

Die Konfiguration eines Akka.NET-Systems kann auf zwei unterschiedliche Arten erfolgen. 
Zum einen kann die HOCON-Konfiguration aus einer externen Datei eingelesen werden, die den vollständigen 
Konfigurationstext enthält. Zum anderen ermöglicht Akka.Hosting die Erstellung der Konfiguration direkt 
über Erweiterungsmethoden innerhalb des .NET-Hostingmodells.

Beide Ansätze wurden im Rahmen dieses Projekts eingesetzt. Für Konsolenanwendungen ist das Laden einer 
separaten HOCON-Datei zweckmäßig, da der Overhead des Hostingmodells dort nicht erforderlich ist. 
In Anwendungen, die auf dem .NET-Hostingmodell basieren, ist die programmgesteuerte Konfiguration über 
Akka.Hosting dagegen besonders vorteilhaft, da sie eine engere Integration in den Lebenszyklus des Hosts 
und eine klar strukturierte Initialisierung des Clusters ermöglicht.

\subsubsection*{HOCON-Konfiguration}

In klassischen Konsolenanwendungen ist es üblich, die Akka.NET-Konfiguration in einer separaten HOCON-Datei 
zu hinterlegen und beim Start der Anwendung einzulesen.

\begin{program}[H]
\caption{Auszug aus der HOCON-Konfiguration des Clients}
\label{prog:hocon-client}
\begin{GenericCode}
akka {
    loglevel = "INFO"
    stdout-loglevel = "OFF"
    loggers = ["Akka.Logger.Serilog.SerilogLogger, Akka.Logger.Serilog"]
    
    actor {
      provider = cluster
      serializers {
        hyperion = "Akka.Serialization.HyperionSerializer, Akka.Serialization.Hyperion"
      }
      serialization-bindings {
        "System.Object" = hyperion
      }
    }
    
    remote.dot-netty.tcp { 
        hostname = "localhost"
        port = 0 
        maximum-frame-size = 2MiB
        send-buffer-size    = 2MiB
        receive-buffer-size = 2MiB
    
    }
    
    cluster {
      roles = ["api"]
      seed-nodes = [
        "akka.tcp://cluster-system@localhost:5000"
      ]
    }
}
\end{GenericCode}
\end{program}

Wie in Programm~\ref{prog:hocon-client} dargestellt, folgt die Konfigurationsdatei der HOCON-Syntax, 
die strukturell an JSON erinnert, jedoch flexibler und für Akka.NET optimiert ist. 
Jede Akka-Konfiguration beginnt mit dem Hauptelement \texttt{akka}, unter dem die zentralen 
Systemparameter definiert werden.

Die initialen Einträge betreffen die Konfiguration des Loggings. Anschließend wird über 
\texttt{actor.provider = cluster} festgelegt, dass dieser Prozess Teil eines verteilten Clusters ist. 
Die Serialisierung der Nachrichten wird mithilfe des Hyperion-Serialisierers konfiguriert, der eine 
effiziente binäre Datenrepräsentation ermöglicht und sich dadurch besonders für Clusterkommunikation eignet.

Der Block \texttt{remote.dot-netty.tcp} enthält die Netzwerkkonfiguration. 
Der Port ist auf \texttt{0} gesetzt, wodurch zur Laufzeit ein freier Port gewählt wird. 
Weitere Parameter wie \texttt{maximum-frame-size} oder die Puffergrößen steuern die maximale Nachrichtengröße 
und die Netzwerkeffizienz der Punkt-zu-Punkt-Kommunikation.

Im Abschnitt \texttt{cluster} werden die Rollen des Knotens sowie die \textit{seed nodes} festgelegt. 
Seed-Knoten dienen als initiale Kontaktpunkte beim Beitritt eines neuen Knotens zum Cluster. 
Nach der ersten Verbindung erfolgt die weitere Clusterentdeckung über das Gossip-Protokoll. 
Die Rollendefinition \texttt{api} legt fest, welche Aufgaben und Aktoren diesem Knoten im Clusterverbund zugeordnet sind.

\subsubsection*{Akka.Hosting}

Anstatt die Konfiguration ausschließlich über externe HOCON-Dateien zu definieren, die beim manuellen Bearbeiten 
anfällig für Fehler sein können, bietet Akka.Hosting die Möglichkeit, die Akka.NET-Konfiguration direkt im 
Anwendungscode aufzubauen. Dadurch lässt sich die Konfiguration eng in die Dependency Injection Pipeline des 
.NET-Hostingmodells integrieren und gemeinsam mit anderen Diensten der Anwendung verwalten.

In diesem Projekt kann die Anwendung wahlweise als monolithischer Prozess oder als verteiltes System mit mehreren 
Clusterknoten ausgeführt werden. Die Konfiguration wurde daher so gestaltet, dass auf Basis der zur Laufzeit 
vergebenen Rollen die jeweils benötigten Komponenten initialisiert werden. Ein entsprechender Ausschnitt ist in 
Programm~\ref{prog:hocon-hosting} dargestellt. Die Rollen werden über Parameter der Konsolenanwendung festgelegt 
und anschließend in der Klasse \texttt{AkkaConfig} ausgewertet.

Um die Konfiguration übersichtlich und wartbar zu halten, wurden zentrale Initialisierungsschritte in 
Erweiterungsmethoden gekapselt. Diese Methoden übernehmen unter anderem die Einrichtung der Clusteroptionen, 
der Remote-Kommunikation sowie der Serialisierungs- und Loggingkonfiguration und binden die jeweiligen Rollen 
wie Ingress, Backend oder Coordinator in das Hostingmodell ein.

\begin{program}[H]
\caption{Auszug aus der Akka.Hosting-Konfiguration}
\label{prog:hocon-hosting}
\begin{CsCode}
public static IServiceCollection UseAkka(this IServiceCollection sp, AkkaConfig akkaHc, ConfigurationManager manager)
{
    string connectionString = manager.GetConnectionString("PostgreSql")!;

    sp.AddAkka(akkaHc.ClusterName, akka =>
    {
        
        akka.UseAkkaLogger();
        akka.UseRemoteCluster(akkaHc);
        akka.UseHyperion();

        if (akkaHc.Roles.Contains(ClusterMemberRoles.Controller.ToStr()))
            akka.RegisterCoordinator(akkaHc);

        if (akkaHc.Roles.Contains(ClusterMemberRoles.Backend.ToStr()))
        {
            akka.RegisterShardRegion(akkaHc);
            akka.RegisterBackendJournal(connectionString);
        }
            

        if (akkaHc.Roles.Contains(ClusterMemberRoles.Ingress.ToStr()))
            akka.RegisterIngress(akkaHc);

        if (!akkaHc.Roles.Contains(ClusterMemberRoles.Controller.ToStr()))
            akka.RegisterControllerProxy();
    });
    return sp;
}
\end{CsCode}
\end{program}

\subsubsection*{Akka.Hosting Koordinator-Initialisierung}

Um exemplarisch zu zeigen, wie die Initialisierung der verschiedenen Rollen erfolgt, ist in Programm~\ref{prog:hocon-hosting-coordinator} 
ein Auszug der Konfiguration für die \textit{Coordinator}-Rolle dargestellt.

Zunächst wird ein Singleton-Aktor des Typs \texttt{ClusterCoordinator} registriert, der zentrale Steuerungsaufgaben 
innerhalb des Clusters übernimmt. Damit andere Komponenten diesen Aktor über die Dependency-Injection-Pipeline 
referenzieren können, wird ein sogenannter \textit{Marker} (\texttt{ClusterCoordinatorMarker}) verwendet. 
Ein solcher Marker dient als eindeutiger Schlüssel, über den sich ein bestimmter Aktor später typsicher abrufen lässt.

Im Anschluss werden weitere Aktoren registriert, die für das Monitoring von Clusterereignissen sowie für die 
Verarbeitung von Ingress- und Shard-bezogenen Ereignissen zuständig sind. Auf diese Weise wird die Beobachtung 
und Verwaltung relevanter Clusterzustände dezentral über spezialisierte Listener-Aktoren umgesetzt.

Die Methode \texttt{resolver.Props<T>()} ist eine Erweiterung von Akka.Hosting und ermöglicht die Erstellung 
von Aktoren unter Nutzung der Dependency Injection. Mit \texttt{system.ActorOf(...)} wird der jeweilige Aktor 
schließlich instanziert und dem Aktorensystem hinzugefügt.

Über \texttt{registry.Register<T>()} wird der erzeugte Aktor anschließend im internen Registry-System von 
Akka.Hosting hinterlegt, damit er später von anderen Diensten oder Modulen abgerufen werden kann.

\begin{program}[H]
\caption{Auszug aus der Akka.Hosting-Koordinator-Konfiguration}
\label{prog:hocon-hosting-coordinator}
\begin{CsCode}
private static void RegisterCoordinator(this AkkaConfigurationBuilder config, AkkaConfig akkaHc)
{
    string role = ClusterMemberRoles.Controller.ToStr();

    config.WithSingleton<ClusterCoordinatorMarker>(
            singletonName: role,
            propsFactory: (_, _, resolver) => resolver.Props<ClusterCoordinator>(),
            options: new ClusterSingletonOptions { Role = akkaHc.Role })
        .WithActors((system, registry, resolver) =>
        {
            var controller = registry.Get<ClusterCoordinatorMarker>();

            registry.Register<ClusterEventListener>(
                system.ActorOf(resolver.Props<ClusterEventListener>(),
                    "cluster-event-listener"));

            registry.Register<IngressListener>(
                system.ActorOf(resolver.Props<IngressListener>(controller),
                    "ingress-listener"));

            registry.Register<ShardListener>(
                system.ActorOf(resolver.Props<ShardListener>(controller),
                    "shard-listener"));
        });
}
\end{CsCode}
\end{program}

\subsubsection*{Akka.Hosting Backend-Initialisierung}

Die \textit{Backend}-Rolle stellt das Herzstück der verteilten Datenverarbeitung dar, da sie die
\texttt{ShardRegion} hostet, in der die einzelnen Fahrerdaten als zustandsbehaftete Entitäten
repräsentiert und verarbeitet werden. Programm~\ref{prog:hocon-hosting-backend} zeigt einen
ausgewählten Ausschnitt der Konfiguration dieser Rolle.

Für die ShardRegion wird die \textit{DistributedData}-Variante des Shardings verwendet.
Hierbei werden die internen Sharding-Metadaten, insbesondere die Zuordnung von Entitäten zu Shards
sowie der aktuelle Aktivierungszustand der Entitäten, über das Modul
\texttt{Akka.DistributedData} repliziert. Dies erhöht die Ausfallsicherheit, da bei einem Knotenverlust
die übrigen Clusterknoten weiterhin einen konsistenten Überblick über die Shard-Verteilung behalten.
Der eigentliche fachliche Zustand der Fahrerdaten wird hingegen durch die persistenten Entitätsaktoren
(\texttt{DriverActorPersistent}) verwaltet und über Akka.Persistence im Journal gespeichert.

Zu Beginn werden die Optionen für das verteilte Sharding konfiguriert. Parameter wie
\texttt{MajorityMinimumCapacity} legen fest, wie viele Clusterknoten für eine Mehrheitsentscheidung
innerhalb von DistributedData erforderlich sind, während \texttt{MaxDeltaElements} bestimmt, wie
umfangreich die über Gossip propagierten Delta-States sein dürfen. Diese Einstellungen beeinflussen das
Verhalten der Replikation insbesondere bei wachsender Anzahl von Entitäten.

Im Anschluss wird die eigentliche ShardRegion registriert. Ein zugehöriger \textit{Marker}
(\texttt{DriverRegionMarker}) ermöglicht den späteren Zugriff über die Dependency-Injection-Pipeline.
Die Entitäten innerhalb der ShardRegion werden als persistent implementierte Aktoren des Typs
\texttt{DriverActorPersistent} ausgeführt. Ein \texttt{MessageExtractor}
(\texttt{DriverMessageExtractor}) ordnet eingehende Nachrichten sowohl den Shards als auch den einzelnen
Entitäten zu und übernimmt damit eine zentrale Rolle in der Lastverteilung.

Zusätzlich werden Optionen wie die automatische Passivierung inaktiver Entitäten sowie die Nutzung des
DistributedData-Modus als Speichermechanismus für Sharding-Metadaten konfiguriert. Mit
\texttt{RememberEntities = true} wird sichergestellt, dass Entitäten nach einem Neustart oder einem
Rebalancing sodass zuvor bekannte Entitäten nach einem Neustart oder Rebalancing automatisch
reaktiviert werden können.

\begin{program}[H]
\caption{Auszug aus der Akka.Hosting-Backend-Konfiguration}
\label{prog:hocon-hosting-backend}
\begin{CsCode}
private static void RegisterShardRegion(this AkkaConfigurationBuilder config, AkkaConfig akkaHc, IMessageExtractor? ex = null)
{
    string role = ClusterMemberRoles.Backend.ToStr();

    var extractor = ex ?? new DriverMessageExtractor();

    config.WithShardingDistributedData(options =>
        {
            options.RecreateOnFailure = true;
            options.MajorityMinimumCapacity = 2;
            options.MaxDeltaElements = 2000;
            options.Durable.Keys = [];
        })
        .WithShardRegion<DriverRegionMarker>(
            typeName: akkaHc.ShardName,
            entityPropsFactory: (_, _, resolver) => _ => resolver.Props<DriverActorPersistent>(),
            messageExtractor: extractor,
            shardOptions: new ShardOptions
            {
                Role = role,
                PassivateIdleEntityAfter = TimeSpan.FromMinutes(5),
                StateStoreMode = StateStoreMode.DData,
                RememberEntities = true
            })
        .WithActors((system, registry, resolver) =>
            registry.Register<TelemetryRegionHandler>(
                system.ActorOf(resolver.Props<TelemetryRegionHandler>(),
                    "telemetry-region-handler")));
}
\end{CsCode}
\end{program}


\subsubsection*{Akka.Hosting Ingress-Initialisierung}

Die \textit{Ingress}-Rolle ist für den Empfang und die Vorverarbeitung der eingehenden Fahrerdaten
zuständig. Programm~\ref{prog:hocon-hosting-ingress} zeigt einen Ausschnitt der Konfiguration dieser Rolle.

Zunächst wird ein Singleton-Aktor des Typs \texttt{IngressHttpActor} registriert, der als Einstiegspunkt für die 
eingehenden Telemetriedaten dient. Die Daten werden von einem vorgelagerten externen Dienst bereitgestellt, der die 
Rohdaten aus der OpenF1-Schnittstelle bezieht und als kontinuierlichen Datenstrom zur Verfügung stellt. Der 
\texttt{IngressHttpActor} übernimmt den Empfang dieses Datenstroms und leitet die empfangenen Nachrichten an die 
nachgelagerte Stream-Pipeline zur weiteren Verarbeitung im Aktorensystem weiter.

Anschließend wird ein ShardRegion-Proxy für die Kommunikation mit der \texttt{ShardRegion} erstellt. 
Hierzu wird ein Marker (\texttt{DriverRegionProxyMarker}) verwendet, über den der Proxy später über die 
Dependency-Injection-Pipeline referenziert werden kann. Der Proxy ermöglicht es den Ingress-Komponenten, 
Nachrichten an die tatsächliche ShardRegion zu senden, ohne direkt an deren physische Instanz gebunden zu sein. 
Dies fördert eine lose Kopplung zwischen Ingress und Backend.

Zusätzlich wird ein \texttt{IngressControllerActor} registriert, der als zentrale Steuerungskomponente 
für die Ingress-Logik dient und die weitere Verarbeitung der eingehenden Daten innerhalb des Aktorensystems koordiniert.

\begin{program}[H]
\caption{Auszug aus der Akka.Hosting-Ingress-Konfiguration}
\label{prog:hocon-hosting-ingress}
\begin{CsCode}
private static void RegisterIngress(this AkkaConfigurationBuilder config, AkkaConfig akkaHc)
{
    string role = ClusterMemberRoles.Ingress.ToStr();
    config
        .WithSingleton<HttpWrapperClientMarker>(
            singletonName: role,
            propsFactory: (_, _, resolver) => resolver.Props<IngressHttpActor>(),
            options: new ClusterSingletonOptions {Role = akkaHc.Role})
        .WithShardRegionProxy<DriverRegionProxyMarker>(
            typeName: akkaHc.ShardName,
            roleName: ClusterMemberRoles.Backend.ToStr(),
            messageExtractor: new DriverMessageExtractor())
        .WithActors((system, registry, resolver) =>
        {
            registry.Register<IngressControllerActor>(
                system.ActorOf(resolver.Props<IngressControllerActor>(),
                    "controller-handler"));
        });
}
\end{CsCode}
\end{program}

\subsubsection*{Akka.Hosting Generelle Remote und Cluster Konfiguration}

Damit ein Aktorensystem als Clusterknoten mit anderen Systemen kommunizieren kann, müssen Remoting und 
Clustering konfiguriert werden. Programm~\ref{prog:hocon-hosting-remote} zeigt eine eigene 
Erweiterungsmethode, die diese Konfiguration bündelt und von allen Rollen gemeinsam genutzt wird. 

Zunächst werden Hostname und Port für das Remote-Modul gesetzt, sodass der Knoten über TCP erreichbar ist. 
Anschließend werden die Clusteroptionen konfiguriert. Dazu gehören die Rollen des Knotens sowie die Seed Nodes, 
über die der Cluster initial aufgebaut wird. Abhängig vom gewählten Startmodus wird entweder eine vollständige 
Seed-Liste oder nur ein initialer Seed-Knoten verwendet.

Für die spätere Nachrichtenverteilung zwischen unabhängigen Aktoren wird außerdem der 
\textit{DistributedPubSub}-Mediator aktiviert. Dieser ermöglicht eine publish/subscribe-basierte Kommunikation, 
ohne dass Sender und Empfänger direkt voneinander wissen müssen. Dies fördert eine lose Kopplung innerhalb des Systems.

Abschließend werden Parameter wie die maximale Nachrichtengröße und die Puffergrößen 
für die TCP-Kommunikation definiert. Diese Einstellungen sind insbesondere bei der Übertragung größerer 
Datenmengen relevant und tragen zur Stabilität und Effizienz der Clusterkommunikation bei.

\begin{program}[H]
\caption{Auszug aus der Akka.Hosting-Remote-Cluster-Konfiguration}
\label{prog:hocon-hosting-remote}
\begin{CsCode}
public static AkkaConfigurationBuilder UseRemoteCluster(this AkkaConfigurationBuilder builder, AkkaConfig config)
{
    builder
        .WithRemoting(
            port: config.Port,
            hostname: config.Hostname)
        .WithClustering(
            new ClusterOptions
            {
                SeedNodes = config.Roles.Count == 1 ? config.SeedNodes : [config.SeedNodes.First()],
                Roles = config.Roles.ToArray()
            })
        .WithDistributedPubSub(role: null!)
        .AddHocon("""
                      akka.remote.dot-netty.tcp {
                        maximum-frame-size  = 2 MiB
                        send-buffer-size    = 2 MiB
                        receive-buffer-size = 2 MiB
                      }
                      """, HoconAddMode.Append);

    return builder;
}

\end{CsCode}
\end{program}

\subsubsection*{Akka.Hosting Persistenzkonfiguration}

Die Persistenz ist ein zentraler Bestandteil der Backend-Rolle, da der Zustand der Fahrerdaten dauerhaft 
gesichert werden muss. Programm~\ref{prog:hocon-hosting-journal} zeigt die Einbindung der 
Persistence-Komponenten in das Aktorensystem mithilfe von Akka.Hosting.

Die Implementierung unterstützt zwei Betriebsmodi.
Zum einen wird eine In-Memory-Persistenz für Testläufe verwendet, die ein schnelles und reproduzierbares 
Verhalten ohne externe Abhängigkeiten ermöglicht. Zum anderen kommt im produktiven Betrieb eine PostgreSQL-basierte 
Persistenz zum Einsatz. Dadurch kann der Zustand der Fahrerdaten auch über Neustarts hinweg konsistent wiederhergestellt werden.

Für den Datenbankzugriff wird Npgsql eingesetzt. Über \texttt{WithSqlPersistence} wird Akka.Persistence.Sql in das 
System integriert und automatisch mit den erforderlichen Journal- und Snapshot-Schemata initialisiert.
Die In-Memory-Variante wird aktiviert, wenn kein Connection-String für die Datenbank
konfiguriert wurde (leerer Connection String), wodurch die Backend-Rolle flexibel
in unterschiedlichen Umgebungen betrieben werden kann.


\begin{program}[H]
\caption{Auszug aus der Akka.Hosting-Journal-Konfiguration}
\label{prog:hocon-hosting-journal}
\begin{CsCode}
private static void RegisterBackendJournal(this AkkaConfigurationBuilder config, string connectionString)
{
    string dbName = "driverRegion";

    if (connectionString is "")
    {
        config.WithInMemoryJournal(journalId: dbName, journalBuilder: _ => { });
        config.WithInMemorySnapshotStore(dbName);
        return;
    }
    
    var dataSource = new NpgsqlDataSourceBuilder(connectionString).Build();

    var dataOptions = new DataOptions()
        .UseDataProvider(
            DataConnection.GetDataProvider(
                ProviderName.PostgreSQL,
                dataSource.ConnectionString) ?? throw new Exception("Could not get data provider"))
        .UseProvider(ProviderName.PostgreSQL)
        .UseConnectionFactory(_ => dataSource.CreateConnection());

    config.WithSqlPersistence(dataOptions, autoInitialize: true, schemaName: "public");

    config.AddStartup((sys, ct) =>
    {
        var c = sys.Settings.Config;
        sys.Log.Info("Journal={0}, Snapshot={1}",
            c.GetString("akka.persistence.journal.plugin"),
            c.GetString("akka.persistence.snapshot-store.plugin"));

        sys.RegisterOnTermination(() => dataSource.Dispose());
        return Task.CompletedTask;
    });
}

\end{CsCode}
\end{program}

\section{Eingangs-Service}

Der Eingangs-Service bildet den Einstiegspunkt in die Datenverarbeitung und empfängt Telemetriedaten über eine
dauerhafte Verbindung zu einem externen Datenprovider. Die Bereitstellung der Telemetriedaten erfolgt dabei über
einen vorgelagerten Dienst, der die Rohdaten aus einer externen Quelle (z.\,B. OpenF1) bezieht und als kontinuierlichen
Datenstrom bereitstellt. Dieser vorgelagerte Dienst ist nicht Bestandteil dieser Arbeit, er dient ausschließlich als
Datenquelle für die Evaluation der entwickelten Stream- und Clusterarchitektur.

Zur Einspeisung der eingehenden Daten wird eine Pipeline mit Akka.Streams aufgebaut. Nach der Materialisierung des 
Stream-Graphs steht eine \texttt{SourceQueue} als Einspeisepunkt zur Verfügung. Über diese Queue können neue Elemente 
kontrolliert in den Stream eingebracht werden. Durch die gewählte Overflow-Strategie Backpressure wird der Produzent 
automatisch verlangsamt, sobald nachgelagerte Verarbeitungsschritte die Daten nicht schnell genug verarbeiten können.

\begin{program}[H]
\caption{Stream-Einspeisung der Daten}
\label{prog:stream-queue-offer}
\begin{CsCode}
await _queue.OfferAsync(dto);
\end{CsCode}
\end{program}

\section{Datenbearbeitung mit Akka.Streams}

Für den Aufbau der Verarbeitungspipeline wird die GraphDSL-API von Akka.Streams verwendet, um den Stream-Graphen 
explizit zu definieren. Beim Start werden mehrere Worker-Aktoren instanziiert, welche die Weiterleitung der 
eingehenden Daten an die ShardRegion übernehmen. Zur Lastverteilung werden die Worker als parallele Senken in den 
Stream integriert und über eine \texttt{Balance}-Stufe angebunden.

Die \texttt{Balance}-Stufe verteilt eingehende Elemente demand-basiert auf die verfügbaren nachgelagerten 
Verarbeitungsstufen. Durch \texttt{waitForAllDownstreams = true} wird sichergestellt, dass die Verteilung erst beginnt, 
nachdem alle nachgelagerten Stufen initiale Nachfrage signalisiert haben. Die anschließende Verteilung erfolgt nicht 
strikt im Round-Robin-Verfahren, sondern abhängig von der jeweils anliegenden Nachfrage beziehungsweise dem aktuellen 
Backpressure-Zustand der einzelnen Worker.

Zur Einspeisung externer Daten in die Verarbeitungspipeline wird eine \texttt{Source.Queue} als Einstiegspunkt des 
Streams verwendet. Diese Queue stellt einen asynchronen Übergabepunkt zwischen der Socket-basierten Datenquelle und 
der internen Stream-Verarbeitung dar. Die gewählte Puffergröße begrenzt die Anzahl zwischengespeicherter Elemente, 
während die Overflow-Strategie \texttt{Backpressure} sicherstellt, dass der Produzent automatisch verlangsamt wird, 
sobald der Puffer ausgelastet ist und nachgelagerte Verarbeitungsschritte die Daten nicht schnell genug verarbeiten 
können.

Zur Unterstützung von Backpressure wird für die Worker-Aktoren eine Sink-Stufe mit Acknowledgement-Mechanismus 
eingesetzt. Mittels \texttt{Sink.ActorRefWithAck} wird jedes Element erst dann als verarbeitet betrachtet, wenn der 
jeweilige Worker eine Bestätigung (\texttt{ack}) zurückmeldet. Dadurch wird verhindert, dass schneller produziert wird 
als verarbeitet werden kann, und der Datenfluss bleibt auch unter Last stabil.

Nach der Definition des Graphen erfolgt die Materialisierung, wodurch die Stream-Komponenten initialisiert und die 
Verbindungen zwischen den einzelnen Stufen hergestellt werden. Anschließend können neue Elemente über die materialisierte 
\texttt{SourceQueue} in den Stream eingespeist werden (vgl.\ Programm~\ref{prog:stream-queue-offer}).


\begin{program}[H]
\caption{Aufbau und Materialisierung des Stream-Graphs}
\label{prog:stream-graph}
\begin{CsCode}
var source = Source.Queue<IOpenF1Dto>(
    bufferSize: 8192,
    overflowStrategy: OverflowStrategy.Backpressure);

var kill = KillSwitches.Single<IOpenF1Dto>();

var graph = RunnableGraph.FromGraph(GraphDsl.Create(
    source, kill,
    (q, ks) => (q, ks),
    (builder, src, ks) =>
    {
        var balancer = builder.Add(
            new Balance<IOpenF1Dto>(workers.Count, waitForAllDownstreams: true));

        builder.From(src).Via(builder.Add(ks)).To(balancer.In);

        for (int i = 0; i < workers.Count; i++)
        {
            var sink = Sink.ActorRefWithAck<IOpenF1Dto>(
                workers[i],
                onInitMessage: StreamInit.Instance,
                ackMessage: StreamAck.Instance,
                onCompleteMessage: StreamCompleted.Instance,
                onFailureMessage: ex => new StreamFailed(ex));

            builder.From(balancer.Out(i)).To(sink);
        }

        return ClosedShape.Instance;
    }));

var (queue, ks) = graph.Run(_mat);
\end{CsCode}
\end{program}

\section{Verarbeitung in der ShardRegion}

Der \texttt{DriverActorPersistent} bildet die zentrale Komponente zur konsistenten Verwaltung des Zustands eines einzelnen 
Fahrers innerhalb einer \texttt{ShardRegion}. Durch die Ableitung von \texttt{ReceivePersistentActor} besitzt er die Fähigkeit, 
Zustandsänderungen als Ereignisse (Events) dauerhaft zu persistieren. Diese Persistenzmechanismen ermöglichen es dem Aktor, 
seinen vollständigen Zustand bei einem Neustart, einem Ausfall einzelner Clusterknoten oder einem Rebalancing des Clusters 
zuverlässig wiederherzustellen.

\subsection{Konstruktor und Wiederherstellung}

Zu Beginn der Aktorinitialisierung werden mithilfe der Methode \texttt{RecoverState} alle zuvor gespeicherten Snapshots sowie 
die nach dem letzten Snapshot aufgetretenen Ereignisse geladen. Dies gewährleistet, dass sich der Zustand des Fahrers auch 
nach einem Ausfall oder einer Migration innerhalb des Clusters vollständig rekonstruieren lässt.

Ein vorhandener \texttt{SnapshotOffer} stellt dabei den zuletzt gespeicherten Zustandsstand bereit, wohingegen alle 
nachfolgenden Ereignisse sequentiell erneut angewendet werden, um den Zustand auf den aktuellen Stand zu bringen.
Der Wiederherstellungsprozess endet mit dem Ereignis \texttt{RecoveryCompleted}. Anschließend wird geprüft, ob der Zustand 
bereits initialisiert wurde. In diesem Fall wechselt der Aktor in das Verhalten \texttt{Initialized}, andernfalls verbleibt 
er im Zustand \texttt{Uninitialized}.

\begin{program}[H]
\caption{Auszug aus dem DriverActorPersistent}
\begin{CsCode}
public DriverActorPersistent(IRequiredActor<TelemetryRegionHandler> handler)
{
    _handler = handler.ActorRef;
    _logger.Info(\$"DriverActorPersistent constructor: {Self.Path.Name}");
    RecoverState();

    Become(Uninitialized);
}

private void RecoverState()
{
    Recover<SnapshotOffer>(offer =>
    {
        _logger.Info(\$"SnapshotOffer for {offer.Snapshot}");
        if (offer.Snapshot is DriverInfoState state)
        {
            _state.RestoreFromSnapshot(state);
            _logger.Info(\$"Recovered snapshot for driver {_state.ToDriverInfoString()}");
        }
    });

    Recover<IHasDriverId>(evt =>
    {
        _state.Apply(evt);
        _logger.Info("Replayed {Event} for {Pid}", evt.GetType().Name, PersistenceId);
    });

    Recover<RecoveryCompleted>(_ =>
    {
        if (_state.IsInitialized) Become(Initialized);
    });
}

\end{CsCode}
\end{program}

\subsection{Initialisierung des Aktors}

Solange der Aktor noch nicht initialisiert wurde, befindet er sich im Verhalten \texttt{Uninitialized}. Dieser Zustand wird 
im Konstruktor über \texttt{Become(Uninitialized)} aktiviert. Die Methode \texttt{Become} ersetzt sämtliche bisher 
registrierten Nachrichtenhandler und ermöglicht damit ein dynamisches, zustandsabhängiges Verhalten des Aktors.

Erst wenn der Aktor eine \texttt{CreateModelDriverMessage} empfängt, wird diese persistiert, auf den internen Zustand 
angewendet und damit die Initialisierung abgeschlossen. Nach erfolgreicher Initialisierung wechselt der Aktor in das 
Verhalten \texttt{Initialized}, in dem er regulär auf weitere fachliche Nachrichten reagieren kann.

Empfängt der Aktor vor Abschluss der Initialisierung eine andere Nachricht, wird er passiviert, um unnötige 
Ressourcenbelegung zu vermeiden. Dies erfolgt über einen \texttt{CommandAny}-Handler, der nicht behandelte 
Nachrichten protokolliert und gleichzeitig die Passivierung der Shard-Entity anstößt.

\begin{program}[H]
\caption{Auszug aus dem DriverActorPersistent}
\begin{CsCode}
private void Uninitialized()
{
    Command<CreateModelDriverMessage>(m =>
    {
        Persist(m, evt =>
        {

            try
            {
                _state.Apply(evt);
                _logger.Info(\$"Initialized driver {_state.ToDriverInfoString()}");
                Sender.Tell(new Status.Success(CreatedDriverMessage.Success(_state.Key)));
                Become(Initialized);
            }
            catch (ArgumentNullException ex)
            {
                _logger.Error(ex, "Failed to initialize driver with message: {Message}", m);
                Sender.Tell(new Status.Failure(ex));
                Context.System.PubSub().Api.Publish(new NotifyStatusFailureMessage(ex.Message));
            }
        });
    });

    Command<StopEntity>(_ => Context.Stop(Self));

    CommandAny(msg =>
    {
        var entityId = Self.Path.Name;
        _logger.Warning(\$"Received {msg.GetType().Name} before initialization for entity {entityId}. Passivating.");

        Sender.Tell(new NotInitializedMessage(entityId));
        Context.Parent.Tell(new Passivate(new StopEntity()));
        Context.System.PubSub().Api.Publish(new NotifyStatusFailureMessage("DriverActor was not init"));
    });   
}
\end{CsCode}
\end{program}

\subsection{Initialisierter DriverActorPersistent}

Nach erfolgter Initialisierung wechselt der Aktor in das Verhalten \texttt{Initialized}. In diesem Zustand reagiert er 
auf verschiedene fachliche Nachrichten, insbesondere auf Änderungen im Fahrerzustand. Jede Änderung wird über die 
Methode \texttt{PersistAndApply} verarbeitet, die die empfangene Nachricht persistiert, auf den internen Zustand anwendet 
und anschließend die aktualisierten Informationen an den \texttt{TelemetryRegionHandler} weiterleitet.
Dies stellt sicher, dass alle nachgelagerten Komponenten jederzeit über den aktuellen Zustand des Fahrers verfügen.

\begin{program}[H]
\caption{Auszug aus dem DriverActorPersistent}
\begin{CsCode}
private void Initialized()
{
    Command<UpdateTelemetryMessage>(m =>
    {
        _logger.Debug("Telemetry: {Id} speed={Speed} t={Ts:o}", _state.Key, m.Speed, m.TimestampUtc);
        PersistAndApply(m);
    });

    // weitere Handler ausgelassen
}

private void PersistAndApply(IHasDriverId element) 
{
    if (!_state.IsInitialized || !KeysMatchOrFail(element.Key))
    {
        Sender.Tell(
            new Status.Failure(
                new DriverInShardNotFoundException(element.Key, \$"Key is not {_state.Key} or initialized")));

        Context.System.PubSub().Api.Publish(new NotifyStatusFailureMessage(\$"Key is not {_state.Key} or initialized"));
        return;
    }

    Persist(element, ev =>
    {
        _state.Apply(ev);
        SendToHandler();
        CreateSnapshot();
    });
    Sender.Tell(new Status.Success(element));
}
\end{CsCode}
\end{program}

\subsection{Persistierung des Zustands}

Damit der Wiederherstellungsprozess effizient bleibt, erzeugt der Aktor in regelmäßigen Abständen einen Snapshot seines 
aktuellen Zustands. Die Methode \texttt{CreateSnapshot} überprüft dazu, ob die aktuelle Sequenznummer ein Vielfaches von 
zehn ist. Nur in diesem Fall wird ein Snapshot erzeugt und gespeichert. Dieses Verfahren reduziert die Anzahl der beim 
Recovery zu verarbeitenden Ereignisse und führt damit zu einer schnelleren Wiederherstellung, ohne bei jeder einzelnen 
Zustandsänderung einen Snapshot zu erzeugen.

\begin{program}[H]
\caption{Auszug aus dem DriverActorPersistent}
\begin{CsCode}
private void CreateSnapshot()
{
    if (LastSequenceNr % 10 == 0)
    {
        _logger.Debug("Creating snapshot for {Pid} at seqNr {Seq}", PersistenceId, LastSequenceNr);
        SaveSnapshot(_state.CopyState());
    }
}
\end{CsCode}
\end{program}

\subsection{Shard-Zuordnung und Rebalancing}

Die Zuordnung eingehender Nachrichten zu den jeweiligen Shards und Entitäten erfolgt über den \texttt{DriverMessageExtractor}, 
der sowohl die Entitäts-ID als auch die Shard-ID aus einer Nachricht ableitet. Dies geschieht über den Standardmechanismus von 
\texttt{Akka.Cluster.Sharding}, der auf dem \texttt{HashCodeMessageExtractor} basiert. Die Shard-Zuordnung ergibt sich dabei 
aus einer Hashfunktion, die von Akka.NET bereitgestellt wird und eine gleichmäßige Verteilung der Entitäten über alle verfügbaren 
Clusterknoten anstrebt.

Eine eigene Rebalancing-Strategie wurde nicht implementiert, da die Standardstrategie von \texttt{Akka.Cluster.Sharding} bereits 
eine effiziente Lastverteilung sicherstellt. Sie verschiebt Shards automatisch, sobald neue Clusterknoten hinzukommen oder 
bestehende Knoten ausfallen, und ermöglicht somit eine robuste Wiederherstellung der Systembalance ohne zusätzlichen Implementierungsaufwand.

\subsection*{Zusammenfassung}

Der \texttt{DriverActorPersistent} kombiniert persistente Ereignisverarbeitung mit einem klar strukturierten, 
zustandsabhängigen Aktormodell innerhalb einer \texttt{ShardRegion}. Während des Recoverys werden sowohl Snapshots als 
auch alle nachfolgenden Ereignisse rekonstruiert, wodurch ein konsistenter Fahrerzustand auch nach Ausfällen oder 
Rebalancing gewährleistet wird. Durch das Wechseln zwischen den Zuständen \texttt{Uninitialized} und \texttt{Initialized} 
wird sichergestellt, dass nur vollständig initialisierte Entities fachliche Nachrichten verarbeiten. Alle Zustandsänderungen 
werden über \texttt{PersistAndApply} als Ereignisse gespeichert und optional mittels periodischer Snapshots ergänzt. Damit 
erfüllt der Aktor die Anforderungen an ein fehlertolerantes, verteiltes und deterministisch rekonstruierbares 
Fahrermanagement im Cluster.

\section{Nachrichtenverteilung im Cluster}

Um bei einer losen Kopplung Nachrichten zwischen Aktoren auszutauschen, wird der \texttt{DistributedPubSub}-Mediator verwendet. 
Dadurch können Aktoren Nachrichten versenden und empfangen, ohne direkte Referenzen aufeinander zu besitzen.

\subsection{Mediator: Nachrichtenempfänger}

Damit ein Aktor Nachrichten über den Mediator empfangen kann, muss er sich mit einem bestimmten Topic beim 
\texttt{DistributedPubSub}-Mediator registrieren. Zur Vereinheitlichung wurde hierfür eine Basisklasse 
implementiert, die die Anmeldung beim Mediator übernimmt. Alle Aktoren, die Nachrichten über ein Topic 
empfangen sollen, erben von dieser Basisklasse.

Während der Anmeldephase werden eingehende Nachrichten zunächst gestasht, bis eine Bestätigung
(\texttt{SubscribeAck}) des \texttt{DistributedPubSub}-Mediators eingetroffen ist. Erst danach wird das
eigentliche Verhalten des Aktors aktiviert und die gestashten Nachrichten werden verarbeitet. Um zusätzlich
Gruppenkommunikation zu unterstützen, erfolgt neben der Anmeldung am Topic eine weitere Anmeldung mit einer
generierten Gruppen-ID. Dadurch können mehrere Aktoren dieselben Nachrichten erhalten, wenn sie mit derselben
Gruppen-ID registriert sind.

\begin{program}[H]
\caption{Auszug aus der Basisklasse für PubSub-Empfänger}
\begin{CsCode}
protected override void PreStart()
{
    _pubSubActorRef = DistributedPubSub.Get(Context.System).Mediator;
    if (_pubSubActorRef.IsNobody())
        throw new ActorNotFoundException("Mediator not connected!");

    _member = PubSubTypeMapping.ToMember(typeof(TTopic)) ?? PubSubMember.All;
    _logger.Info(\$"Mediator is trying to connected to topic {_member.ToStr()}");

    _pubSubActorRef.Tell(new Subscribe(_member.ToStr(), Self));
    _pubSubActorRef.Tell(new Subscribe(_member.ToStr(), Self, GenerateGroupId(_member)));
}
\end{CsCode}
\end{program}

Nach der Anmeldung wird auf die Bestätigung durch den Mediator gewartet. Solange diese Bestätigung noch nicht 
eingetroffen ist, werden alle Nachrichten gestasht. Sobald die erwartete Anzahl an \texttt{SubscribeAck}-Nachrichten 
empfangen wurde, werden alle gesammelten Nachrichten entstapelt und das eigentliche Verhalten des Aktors aktiviert.

\begin{program}[H]
\caption{Auszug aus der Basisklasse für PubSub-Empfänger}
\begin{CsCode}
private void HandleAckSub()
{
    Receive<SubscribeAck>(msg =>
    {
        _logger.Info(\$"Grab Ack for {msg.Subscribe.Topic} with group ({msg.Subscribe.Group})");

        Become(() =>
        {
            Activated();
            Stash.UnstashAll();
        });
    });

    ReceiveAny(_ => Stash.Stash());
}
\end{CsCode}
\end{program}

\subsection{Mediator: Nachrichtensender}

Zum Versenden von Nachrichten wird der \texttt{DistributedPubSub}-Mediator referenziert und über eine 
\texttt{Publish}-Nachricht ein bestimmtes Topic adressiert. 
Um sicherzustellen, dass Nachrichten stets mit einem konsistenten und korrekt definierten Topic gesendet werden, 
wurden mehrere typisierte Zugriffsmethoden definiert.

Diese Methoden (\texttt{Api}, \texttt{Backend}, \texttt{Ingress}, \texttt{Controller}) stellen jeweils einen 
vordefinierten logischen Kommunikationskanal bereit. 
Anstatt frei formulierte Topic-Strings zu verwenden, wird das jeweils zugehörige Topic intern über die 
Zuordnung des entsprechenden Mitglieds bestimmt und anschließend über den Mediator veröffentlicht.

Auf diese Weise entsteht eine string-freie und fehlerresistente Mechanik zur Nachrichtenverteilung, 
die sowohl eine lose Kopplung der Aktoren als auch eine einheitliche Struktur der verwendeten Topics im gesamten 
System sicherstellt.

Programm~\ref{prog:Erweiterungsmethode Mediator} zeigt exemplarisch die Verwendung dieser Methoden.

\begin{program}[H]
\caption{Auszug aus der Erweiterungsmethode für PubSub-Sender}
\label{prog:Erweiterungsmethode Mediator}
\begin{CsCode}
Context.PubSub().Api.Publish(new NotifyDriverStateMessage(msg.Key, msg.State));
Context.PubSub().Backend.Publish(new NotifyDriverStateMessage(msg.Key, msg.State));
\end{CsCode}
\end{program}

\section{Cluster-Steuerung und Fehlertoleranz}

Die Steuerung der Clusterverfügbarkeit und das Zusammenspiel zwischen ShardRegion und Ingress-Komponenten werden durch 
eine explizite Koordinationsschicht realisiert. Diese Schicht besteht im Wesentlichen aus dem \texttt{ClusterCoordinator}, 
dem \texttt{ShardListener}, dem \texttt{IngressListener} sowie einem \texttt{ClusterEventListener}. Ziel ist es, 
den aktuellen Zustand der relevanten Clusterrollen (Backends und Ingress-Knoten) zu überwachen und darauf aufbauend die 
Erreichbarkeit der ShardRegion gegenüber dem Ingress-Datenstrom zu steuern.

\subsection{ClusterCoordinator}

Der \texttt{ClusterCoordinator} übernimmt die zentrale Rolle der Zustands- und Verfügbarkeitskoordination zwischen der 
ShardRegion und den Ingress-Komponenten. Er empfängt Statusmeldungen sowohl vom \texttt{ShardListener} als auch 
vom \texttt{IngressListener} und verwaltet intern den aktuellen Erreichbarkeitsstatus der ShardRegion. Ändert sich 
dieser Zustand, benachrichtigt der \texttt{ClusterCoordinator} unmittelbar den \texttt{IngressListener}, damit die Ingress-Knoten 
ihren Datenfluss entsprechend anpassen können. Dadurch wird sichergestellt, dass Daten nur dann an die ShardRegion 
gesendet werden, wenn diese tatsächlich verfügbar ist.

Die Ermittlung des Shard-Status erfolgt entweder reaktiv durch eingehende Statusmeldungen oder proaktiv über explizite 
Statusabfragen. Der \texttt{ClusterCoordinator} selbst ist nicht an der Verarbeitung der Daten beteiligt, sondern fungiert 
als administrative Instanz, die den Ingress-Komponenten mitteilt, ob eine Weiterleitung von Nachrichten an die ShardRegion 
zulässig ist. Zusätzlich stellt er Informationen über die derzeit verfügbare Anzahl an Clusterknoten bereit.

\begin{program}[H]
\caption{Auszug aus dem ClusterCoordinator}
\begin{CsCode}
Receive<ShardConnectionUpdateMessage>(msg =>
{
    _hasShardRegion = msg.IsShardOnline;
    var con = _hasShardRegion ? "connected" : "disconnected";
    _logger.Debug(\$"Shard connection changed. Shard {con}");
    _ingressListener.Tell(new IngressConnectionCanActivated(_hasShardRegion));
});

ReceiveAsync<IngressConnectivityRequest>(async _ =>
{
    if (!_hasShardRegion)
    {
        var res = await _shardListener
            .Ask<ShardConnectionUpdateMessage>(ShardConnectionRequest.Instance);
        _hasShardRegion = res.IsShardOnline;
    }

    _logger.Debug(\$"Ingress activate request. Shard active: {_hasShardRegion}");
    Sender.Tell(new IngressConnectivityResponse(_hasShardRegion));
});
\end{CsCode}
\end{program}

\subsection{ShardListener: Verfügbarkeit der ShardRegion}

Der \texttt{ShardListener} ist für die kontinuierliche Überwachung der Backend-Knoten verantwortlich, auf denen die ShardRegion 
ausgeführt wird. Zu diesem Zweck verwaltet er eine interne Menge aller aktuell aktiven Backend-Adressen. Änderungen in der Zusammensetzung 
dieser Menge, etwa durch das Hinzukommen oder Wegfallen eines Knotens, werden über die Methode \texttt{SendCountUpdate} an den 
\texttt{ClusterCoordinator} gemeldet.

Um eine übermäßige Anzahl an Statusmeldungen zu vermeiden, insbesondere bei kurzzeitigen oder rasch aufeinanderfolgenden Clusterereignissen, 
wird ein Entlastungsmechanismus eingesetzt, der funktional einer Debounce-Strategie entspricht. Dabei werden Statusänderungen nicht sofort 
nach ihrem Auftreten weitergeleitet, sondern zunächst verzögert gesammelt. Erst wenn innerhalb eines kurzen Zeitfensters keine weiteren 
Änderungen auftreten, wird eine konsolidierte Aktualisierung an den \texttt{ClusterCoordinator} gesendet. Dies reduziert die 
Kommunikationslast erheblich und verhindert, dass der \texttt{ClusterCoordinator} mit einer großen Anzahl kurzlebiger Statusmeldungen 
überflutet wird.

\begin{program}[H]
\caption{Auszug aus dem ShardListener}
\begin{CsCode}
Receive<IncreaseClusterMember>(msg =>
{
    Logger.Debug("Increase counter");
    _activeBackends.Add(msg.ClusterMemberRef);
    SendCountUpdate(new ShardConnectionUpdateMessage(_activeBackends.Count > 0));
});

Receive<DecreaseClusterMember>(msg =>
{
    Logger.Debug("Decrease counter");
    _activeBackends.Remove(msg.ClusterMemberRef);
    SendCountUpdate(new ShardConnectionUpdateMessage(_activeBackends.Count > 0));
});

Receive<ShardCountRequest>(_ =>
    Sender.Tell(new ShardCountResponse(_activeBackends.Count)));
\end{CsCode}
\end{program}

\subsection{IngressListener: Verwaltung und Benachrichtigung der Ingress-Knoten}

Der \texttt{IngressListener} übernimmt analog zum \texttt{ShardListener} die Aufgabe, den aktuellen Zustand der Ingress-Knoten 
zu überwachen und eine konsistente Sicht auf deren Verfügbarkeit bereitzustellen. Zu diesem Zweck verwaltet er eine interne 
Menge aller aktiven Ingress-Instanzen und aktualisiert diese basierend auf den vom \texttt{ClusterEventListener} weitergeleiteten 
Cluster-Ereignissen.

Neben dieser Überwachungsfunktion fungiert der \texttt{IngressListener} zugleich als zentrale Anlaufstelle für Anfragen seitens 
der Ingress-Knoten. Er beantwortet insbesondere Rückfragen zur aktuellen Erreichbarkeit der \texttt{ShardRegion} und dient somit 
als Vermittler zwischen Ingress-Schicht und Backend-Struktur. Änderungen im Status der \texttt{ShardRegion} werden unmittelbar 
per Publish-Subscribe an alle registrierten Ingress-Knoten weitergegeben, um deren Sendeverhalten entsprechend zu steuern.

\begin{program}[H]
\caption{Auszug aus dem IngressListener}
\begin{CsCode}
Receive<IngressConnectionCanActivated>(msg =>
{
    var isOnline = msg.IsShardOnline ? "online" : "offline";
    Logger.Debug(\$"Auto send to shard is {isOnline} and ingress will be notified!");
    Context.PubSub().Ingress.Publish(new NotifyIngressShardIsOnline(msg.IsShardOnline));
});

Receive<IncreaseClusterMember>(msg =>
{
    Logger.Debug("Increase counter");
    _activeIngress.Add(msg.ClusterMemberRef);
    SendCountUpdate(new IngressConnectionUpdateMessage(_activeIngress.Count > 0));
});
\end{CsCode}
\end{program}

\subsection{ClusterEventListener: Verarbeitung und Weiterleitung von Cluster-Events}

Der \texttt{ClusterEventListener} ist unmittelbar an das Cluster-Subsystem angebunden und abonniert zentrale Ereignisse des 
Cluster-Lifecycles. Hierzu zählen insbesondere \texttt{MemberUp} und \texttt{MemberRemoved}, die das Hinzufügen bzw. Entfernen 
eines Clusterknotens signalisieren, sowie Erreichbarkeitsänderungen wie \texttt{UnreachableMember} und \texttt{ReachableMember}.

Die eingehenden Ereignisse werden anhand der Rollen des betroffenen Clusterknotens analysiert. Auf dieser Grundlage entscheidet 
der \texttt{ClusterEventListener}, welcher spezialisierte Listener (z. B. \texttt{ShardListener}, \texttt{IngressListener}) 
informiert werden muss. Dadurch fungiert der \texttt{ClusterEventListener} als zentrale Verteilerinstanz, die Cluster-Statusänderungen 
effizient an die jeweils relevanten Systemkomponenten weiterleitet. Die Zuordnung erfolgt über die Rollen des jeweiligen Knotens, 
die zur Klassifizierung seiner Funktion im Cluster dienen.

\begin{program}[H]
\caption{Auszug aus dem ClusterEventListener}
\begin{CsCode}
Receive<ClusterEvent.MemberUp>(u =>
{
    _logger.Info(\$"Cluster Member is Up {u}, {string.Join(',', u.Member.Roles)}");
    foreach (var s in u.Member.Roles)
        Broadcast(ClusterMemberExtension.Parse(s),
                  new IncreaseClusterMember(u.Member.Address));
});

Receive<ClusterEvent.MemberRemoved>(r =>
{
    _logger.Info(\$"Cluster Member is Removed {r}, {string.Join(',', r.Member.Roles)}");
    foreach (var s in r.Member.Roles)
        Broadcast(ClusterMemberExtension.Parse(s),
                  new DecreaseClusterMember(r.Member.Address));
});
\end{CsCode}
\end{program}

\subsection{Fehlertoleranzkonzept der Koordinationsschicht}

Die Koordinationsschicht ist darauf ausgelegt, automatisch auf Änderungen im Clusterzustand zu reagieren und dadurch die Erreichbarkeit der 
ShardRegion zuverlässig zu bestimmen. Grundlage hierfür bilden die in Akka.NET integrierten Fehlertoleranzmechanismen, insbesondere das 
Gossip-Protokoll sowie die Erreichbarkeitsüberwachung mittels periodischer Herzschlagsignale.

Akka.NET verbreitet Clusterzustände kontinuierlich über Gossip-Nachrichten, die in regelmäßigen Intervallen zufällig zwischen den Knoten 
ausgetauscht werden. Auf diese Weise konvergiert der Wissensstand aller Clusterteilnehmer sukzessive zu einer gemeinsamen Sicht auf den 
Systemzustand, ohne dass ein zentraler Koordinator erforderlich ist. Parallel dazu überwacht das Cluster-Subsystem die Erreichbarkeit der 
einzelnen Knoten anhand von Heartbeats. Bleiben diese über einen bestimmten Zeitraum aus oder treten nur noch unregelmäßig auf, wird der 
entsprechende Knoten zunächst als \texttt{Unreachable} markiert. Persistiert dieser Zustand, stuft das Cluster den Knoten als ausgefallen 
ein und kennzeichnet ihn als \texttt{MemberRemoved} \parencite{akka_cluster_failure_overview}.

Die Listener-Komponenten der Koordinationsschicht werten die dadurch generierten Ereignisse aus und aktualisieren ihre interne Sicht auf 
die Clusterverfügbarkeit. Auf dieser Basis kann der \texttt{ClusterCoordinator} unmittelbar reagieren, indem er beispielsweise den 
Ingress-Datenstrom deaktiviert, sobald die ShardRegion nicht mehr erreichbar ist. Dieses Verhalten ermöglicht eine fehlertolerante 
Betriebsweise, bei der das Gesamtsystem trotz einzelner Knotenausfälle konsistent weiterarbeitet und verhindert wird, dass Nachrichten an 
eine nicht verfügbare Backend-Struktur gesendet werden.

\section{Client- und Visualisierungsschicht}

Zur Veranschaulichung der im System erzeugten und verarbeiteten Daten wurde eine konsolenbasierte Client-Anwendung entwickelt, die als 
leichtgewichtige Visualisierungsschicht dient. Der Client verbindet sich direkt mit dem Aktorensystem und ermöglicht die Interaktion mit 
verschiedenen Komponenten, etwa zur Abfrage von Systemmetriken oder zur Steuerung der Datenverarbeitung.

Eine separate API-Schicht wurde im Rahmen dieser Arbeit noch nicht umgesetzt, wird jedoch als sinnvolle Erweiterungsmöglichkeit betrachtet. 
Eine solche Schnittstelle ließe sich auf Basis der bestehenden Architektur vergleichsweise einfach realisieren, da sie über eine Anbindung 
an das Aktorensystem dieselben Nachrichten empfangen und versenden könnte wie der aktuelle Konsolen-Client. Dadurch wäre es möglich, 
externe Anwendungen oder Visualisierungstools einzubinden und die Daten des Systems auch außerhalb der Konsolenoberfläche verfügbar zu machen.

\subsection{Konsolenbasierter Monitoring-Client}

Die entwickelte Konsolenanwendung dient als Monitoring-Client und ermöglicht eine übersichtliche Darstellung der im System erzeugten Metriken 
und Statusinformationen. Für die strukturierte und visuell ansprechende Aufbereitung der Daten kommt das Drittanbieterpaket \texttt{Spectre.Console} 
zum Einsatz, das erweiterte Funktionalitäten für die Gestaltung interaktiver und formatiert strukturierter Konsolenoberflächen bereitstellt.

Abbildung~\ref{fig:console_client} zeigt einen Screenshot der Anwendung während der Laufzeit und veranschaulicht die textbasierte Visualisierung 
der Systemzustände.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./assets/console-client.png}
  \caption{Konsolenbasierter Monitoring-Client (\enquote{Bachelor Akka Client})}
  \label{fig:console_client}
\end{figure}

Die Oberfläche ist in mehrere Bereiche gegliedert:

\begin{itemize}
  \item \textbf{Throughput}: Anzeige der aktuell verarbeiteten Nachrichtenrate (Nachrichten pro Sekunde), 
        der insgesamt verarbeiteten Nachrichten, der Laufzeit sowie einer einfachen Fehlerrate. 
        Zusätzlich werden Latenz-Quantile (p50, p95, p99) visualisiert, sofern Messungen aktiv sind.
  \item \textbf{Latency}: Detailliertere Darstellung der gemessenen Antwortzeiten in Millisekunden, 
        ebenfalls aufgeteilt nach p50, p95 und p99 sowie Minimal- und Maximalwert.
  \item \textbf{Cluster \& Shards}: Übersicht über den aktuellen Clusterzustand, insbesondere 
        die Anzahl aktiver Knoten, Shards und Entities sowie den aktuell verwendeten Pipeline-Modus.
  \item \textbf{Race-Informationen}: Anzeige kontextbezogener Domäneninformationen, etwa zur aktuell 
        ausgewählten Rennstrecke (Location, Country).
  \item \textbf{Controls}: Liste der verfügbaren Tastaturbefehle (z.\,B. Verbindungsaufbau, Start/Stop 
        von Messungen, Wechsel des Rennens oder der Pipeline-Konfiguration).
\end{itemize}

Der Client kommuniziert hierzu direkt mit dem Cluster und bezieht sowohl Systemmetriken (z.\,B. Cluster- und Shard-Zustand) als auch domänenspezifische Daten. 
Er ist nicht als Endanwenderoberfläche konzipiert, sondern als leichtgewichtige Monitoring- und Debugging-Komponente, die es ermöglicht, die Funktionsweise 
des verteilten Systems im Rahmen dieser Arbeit transparent und nachvollziehbar darzustellen.

\section{Zusammenführung der Komponenten}

In diesem Abschnitt wird das Zusammenspiel der zuvor beschriebenen Komponenten, \texttt{ClusterCoordinator}, \texttt{ShardRegion}, 
Ingress-Schicht sowie Monitoring-Client, im Gesamtsystem erläutert.

\subsection{Ablauf aus Sicht des Clusters}

Nach dem Start des Clusters initialisieren sich die beteiligten Knoten entsprechend ihrer konfigurierten Rollen. Die ShardRegion wird auf 
den Backend-Knoten gestartet und übernimmt die Verwaltung der persistierten Fahrerinstanzen (DriverActorPersistent). Parallel dazu 
verbinden sich die Ingress-Knoten mit dem ClusterCoordinator, um Informationen über die Verfügbarkeit der ShardRegion zu erhalten.

Sobald mindestens eine ShardRegion verfügbar und ein Ingress-Knoten aktiv ist, erteilt der ClusterCoordinator die Freigabe 
für die Weiterleitung von Daten vom Ingress an die ShardRegion. Wählt der Monitoring-Client anschließend ein Rennen aus, erhält der 
Ingress-Dienst die Anweisung, die entsprechenden Telemetriedaten über OpenF1 zu beziehen und in einen Akka.Streams-Graph einzuspeisen. Innerhalb 
des Stream-Graphs werden die Rohdaten aufbereitet und in ein einheitliches Nachrichtenformat konvertiert, das von der ShardRegion 
verarbeitet werden kann.

Die konvertierten Nachrichten werden anschließend über den ShardRegionProxy an die ShardRegion übermittelt. Diese prüft die 
Nachricht und ordnet sie anhand der Fahrer-ID der zuständigen DriverActorPersistent-Instanz zu. Der Aktor verarbeitet die eingehende 
Nachricht, aktualisiert seinen Zustand, persistiert die Änderungen und sendet schließlich aktualisierte Fahrerdaten an den 
Monitoring-Client.

\subsection{Ablauf aus Sicht der Datenübertragung}

Der Datenfluss beginnt im Ingress-Service, der einen kontinuierlichen Telemetriedatenstrom vom vorgelagerten Datenprovider entgegennimmt 
(z.\,B. basierend auf OpenF1) und in einen Akka.Streams-Graph überführt.

Die Übergabe an die ShardRegion erfolgt über einen ShardRegionProxy. Der Proxy stellt einen transparenten Zugriff auf
die ShardRegion bereit, ohne dass die Ingress-Komponenten an eine konkrete physische Instanz gebunden sind. Die Zuordnung
der Nachrichten zu Shards und Entitäten erfolgt über den \texttt{MessageExtractor} auf Basis der Fahrer-ID. Dadurch werden
Nachrichten deterministisch an die zuständige Entity (\texttt{DriverActorPersistent}) geroutet, die Platzierung der Shards
auf Backend-Knoten wird durch Cluster Sharding verwaltet und kann sich durch Rebalancing dynamisch ändern.

\subsection{Ablauf aus Sicht der Fehlertoleranz}

Die Fehlertoleranz wird durch die in Akka.NET integrierten Mechanismen zur Clusterüberwachung sichergestellt. Fällt ein Clusterknoten aus oder reagiert 
nicht mehr, erkennt das Gossip-Protokoll den Zustand und markiert den betreffenden Knoten zunächst als \texttt{Unreachable}. Persistiert dieser Zustand, 
wird der Knoten als \texttt{MemberRemoved} eingestuft und aus dem Cluster entfernt.

Der \texttt{ClusterEventListener} empfängt diese Ereignisse und informiert \texttt{ShardListener} und \texttt{IngressListener} über die entsprechenden 
Änderungen. Der \texttt{ShardListener} aktualisiert daraufhin seine interne Sicht auf die Backend-Knoten und leitet diese Information an den 
\texttt{ClusterCoordinator} weiter. Dieser informiert anschließend den \texttt{IngressListener}, der wiederum die Ingress-Knoten über die neue 
Erreichbarkeitssituation der ShardRegion benachrichtigt. Solange keine funktionsfähige ShardRegion verfügbar ist, senden die Ingress-Knoten 
keine Daten an den Cluster, wodurch inkonsistente Zustände und Nachrichtenverluste verhindert werden.

Fällt eine einzelne \texttt{DriverActorPersistent}-Instanz aus, wird diese von der ShardRegion automatisch neu gestartet. Aufgrund der Persistierung 
ihres vorherigen Zustands kann die Aktor-Instanz ihren letzten konsistenten Zustand rekonstruieren und die Verarbeitung fortsetzen, ohne dass Daten verloren 
gehen oder eine manuelle Wiederherstellung erforderlich ist.
